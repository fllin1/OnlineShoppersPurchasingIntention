{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **0.Librairies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from scipy.stats import ks_2samp\n",
    "# Modèles\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# XGBoost et LightGBM\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# UCI ML Repo\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **I. Formulation du problème**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Définition du problème**\n",
    "\n",
    "Nous allons utiliser le dataset [Online Shoppers Purchasing Intention](https://archive.ics.uci.edu/dataset/468/online+shoppers+purchasing+intention+dataset) pour prédire si une session d'un utilisateur aboutira à un achat ou non. Il s'agit donc d'un problème de **classification binaire**.\n",
    "\n",
    "- **Objectif :** Construire un modèle prédictif capable de classer les sessions en deux catégories :\n",
    "    - **Revenue = True** : la session se termine par un achat.\n",
    "    - **Revenue = False** : la session ne se termine pas par un achat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Formulation mathématique**\n",
    "\n",
    "Soit :\n",
    "- Un ensemble de données $X=\\{x_1,x_2,...,x_n\\}$ où chaque xi est un vecteur de caractéristiques représentant une session. \n",
    "- Une variable cible $Y=\\{y_1, y_2, ..., y_n\\}$ où $y_i \\in \\{0, 1\\}$ (0 pour \"pas d'achat\", 1 pour \"achat\").\n",
    "\n",
    "Le but est de trouver une fonction $f : X \\rightarrow Y$ telle que pour un nouvel exemple $x, f(x)$ prédit correctement $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **II. Exploration du dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Informations according to the official documentation:*\n",
    "\n",
    "The dataset consists of feature vectors belonging to 12,330 sessions. \n",
    "\n",
    "The dataset was formed so that each session would belong to a different user in a 1-year period to avoid any tendency to a specific campaign, special day, user profile, or period.\n",
    "\n",
    "It cointains no missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des données \n",
    "online_shoppers_purchasing_intention_dataset = fetch_ucirepo(id=468) \n",
    "  \n",
    "# Récupérations des variables\n",
    "variables = online_shoppers_purchasing_intention_dataset.variables \n",
    "X = online_shoppers_purchasing_intention_dataset.data.features \n",
    "y = online_shoppers_purchasing_intention_dataset.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des données\n",
    "variables.to_csv('../data/online_shoppers_purchasing_intention_dataset.csv', index=False)\n",
    "X.to_csv('../data/features.csv', index=False)\n",
    "y.to_csv('../data/targets.csv', index=False)\n",
    "\n",
    "# Chargement des données\n",
    "variables = pd.read_csv('../data/online_shoppers_purchasing_intention_dataset.csv')\n",
    "X = pd.read_csv('../data/features.csv')\n",
    "y = pd.read_csv('../data/targets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Analyse exploratoire des données**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette partie est dédiée à la **compréhension générale des variables** et consistera en l'étude des:\n",
    "- **Variables numériques :** Analyse des distributions (moyenne, médiane, écart-type).\n",
    "- **Variables catégorielles :** Comptage des occurrences, encodage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a. Variables Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supproime les variables vides\n",
    "variables = variables[['name', 'role', 'type', 'missing_values']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **b. Target: Revenue (y)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y['Revenue'].sum()/len(y))\n",
    "\n",
    "# On affiche la distribution de la variable cible\n",
    "sns.countplot(x='Revenue', data=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que seulement **14,5%** des utilisateurs ont acheté."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **c. Features (X)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Informations générales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque en effet qu'il n'y a aucune valeur manquante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Visualisations initiales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a. Visualisation des features numériques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "n = len(numeric_features)\n",
    "cols = 4\n",
    "rows = n // cols + (n % cols > 0)\n",
    "\n",
    "# Créer la figure et les sous-graphes\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "for i, feature in enumerate(numeric_features):\n",
    "    sns.histplot(X[feature], kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution de {feature}')\n",
    "for i in range(n, len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La majorité des distributions ont une forte concentration de données **proches de zéro**, particulièrement pour les interactions avec des pages spécifiques du site (pages administratives, informatives et produits). On peut supposer que que seulement une petite fraction des utilisateurs s'engagent sur ce types de pages.\n",
    "\n",
    "- L'analyse des taux de sortie et de rebond pourrait aider à **identifier des problèmes d'engagement**, notamment si certains types de pages (comme les pages de produits ou informatives) ont des taux de sortie plus élevés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "n = len(categorical_features)\n",
    "cols = 3\n",
    "\n",
    "# Créer la figure et les sous-graphes\n",
    "fig, axes = plt.subplots(1, cols, figsize=(16, 4))\n",
    "axes = axes.flatten()\n",
    "for i, feature in enumerate(categorical_features):\n",
    "    sns.histplot(X[feature], kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution de {feature}')\n",
    "for i in range(n, len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque plusieurs choses:\n",
    "- Un comportement de **saisonalité**, avec des pics au printemps et en automne.\n",
    "  \n",
    "- Une présence plus importante de **visiteurs réccurents**, cela indique que le site a un bon taux de fidélisation.\n",
    "  \n",
    "- Les achats semblent assez **équitablement répartis** au cours de la semaine, on retrouve une proportion cohérente d'environ 5/7 en semaine et 2/7 le week-end. Cela pourrait indiquer que le site est autant utilisé pour des activités professionnelles que récréatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aucune variable nulle dans les **features** et le **target** dataset, nous pouvons donc directement travailler sur les données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **b. Détection de corrélations :**\n",
    "- **Matrice de corrélation** pour identifier les variables fortement liées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "correlation = X[numeric_features].corr()\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm')\n",
    "plt.title('Matrice de corrélation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corrélations fortes :**\n",
    "\n",
    "- **ProductRelated** et **ProductRelated_Duration** (0.86) : Il est logique que le nombre de pages de produits visitées soit fortement corrélé avec la durée passée sur ces pages. Plus les utilisateurs visitent de pages produits, plus ils passent de temps sur ces pages.\n",
    "\n",
    "- **BounceRates** et **ExitRates** (0.91) : Ces deux variables sont également très corrélées. Cela indique que les sessions avec un taux de rebond élevé ont tendance à se terminer rapidement (forte probabilité de quitter le site après avoir consulté peu de pages).\n",
    "\n",
    "**Corrélations modérées :**\n",
    "\n",
    "- **Informational** et **Informational_Duration** (0.62) : De même, une corrélation assez élevée entre le nombre de pages informatives visitées et la durée passée sur ces pages, ce qui est également intuitif.\n",
    "\n",
    "- **Administrative** et **Administrative_Duration** (0.6) : La relation entre le nombre de pages administratives visitées et la durée passée sur ces pages est modérée. Plus les utilisateurs interagissent avec des pages administratives, plus ils passent de temps sur ces pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utiliser `sns.violinplot` pour observer les distributions de chaque **feature** contre le **target**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([X, y], axis=1)\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i, feature in enumerate(numeric_features, 1):\n",
    "    plt.subplot(4, 4, i)\n",
    "    sns.violinplot(x='Revenue', y=feature, data=data, split=True)\n",
    "    plt.title(f'{feature} vs Revenue')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Pages produits** : Les variables liées aux pages produits (*ProductRelated* et *ProductRelated_Duration*) sont les meilleures variables pour différencier les utilisateurs générant des revenus de ceux qui n'en génèrent pas. Plus un utilisateur interagit avec les pages produits, plus il est susceptible de générer un revenu.\n",
    "\n",
    "- **Taux de rebond** et **taux de sortie** : Les utilisateurs qui génèrent des revenus tendent à avoir des taux de rebond et taux de sortie plus faibles, ce qui indique un engagement plus profond avec le site.\n",
    "\n",
    "- **PageValues** : C’est l'une des variables les plus discriminantes, les utilisateurs générant des revenus ayant des valeurs de page beaucoup plus élevées.\n",
    "\n",
    "- Les autres facteurs n'ont pas un impact significatif sur la génération de revenus, du moins dans cette visualisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **III. Modélisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Prétraitement des données**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a. Encodage des variables catégorielles**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir les variables binaires en entiers :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Weekend'] = data['Weekend'].astype(int)\n",
    "data['Revenue'] = data['Revenue'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "One-Hot Encoding pour les variables catégorielles avec plus de deux catégories :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['Month', 'VisitorType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **b. Normalisation ou standardisation des variables numériques**\n",
    "Standardisation pour uniformiser l'échelle des variables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data[numeric_features] = scaler.fit_transform(data[numeric_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **c. Gestion du déséquilibre des classes**\n",
    "SMOTE pour sur-échantillonner la classe minoritaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Revenue', axis=1)\n",
    "y = data['Revenue']\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **d. Division des données en ensembles d'entraînement et de test**\n",
    "Séparation les données en ensembles d'entraînement et de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, \n",
    "    y_resampled, \n",
    "    test_size=0.3, # 30% des données pour le test\n",
    "    random_state=42, # Fixer le random_state pour obtenir les mêmes résultats\n",
    "    stratify=y_resampled # Stratification pour conserver la distribution de la variable cible\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Algorithmes de Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utliser les méthodes suivantes classiques puis comparer leurs performances:\n",
    "- Régression Logistique\n",
    "- Arbre de Décision\n",
    "- Forêt Aléatoire\n",
    "- XGBoost\n",
    "- Réseau de Neurones avec PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a. Implémentation des modèles**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Régression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arbre de Décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forêt Aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RN avec PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les données en tenseurs\n",
    "X_train_tensor = torch.tensor(X_train.values.astype(float), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values.astype(float), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Créer des DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.layer1(x))\n",
    "        out = self.relu(self.layer2(out))\n",
    "        out = self.output(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size=X_train.shape[1])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        all_preds.extend(predicted.numpy())\n",
    "    \n",
    "    print(f'Accuracy du réseau sur les données de test : {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **b. Évaluation des modèles**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La précision seule perd en fiabilité dans un scénario où les classes sont déséquilibrées. Nous allons donc utiliser 3 méthodes d'évaluation qui sont particulirement pertinentes dans ce cas, et importées de `sklearn.metrics`: \n",
    "\n",
    "- `classification_report`:\n",
    "  - la **précision** du modèle (proportion des prédictions positives qui sont correctes).\n",
    "  - le **recall** (proportion des vrais positifs qui sont correctement prédits).\n",
    "  - le **f1-score** (moyenne harmonique de la précision et du rappel).\n",
    "\n",
    "- `confusion_matrix`: affiche au sein d'une matrice 2x2 les **True Positives**, **True Negatives**, **False Positives** et **False Negatives**.\n",
    "\n",
    "- `roc_auc_score`: **ROC** (Receiver Operating Characteristic) est le tracé de **True Positive Ratio** contre **False Positive Ratio** pour chaque seuil de classification possible entre 0 et 1 (dans la pratique, à des intervalles choisis). L'**AUC** est l'aire sous la courbe ROC, plus il est proche de 1, plus le modèle est performant, et s'il est proche de 0.5, cela équivaut à une classification aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {\n",
    "    'Régression Logistique': y_pred_lr,\n",
    "    'Arbre de Décision': y_pred_dt,\n",
    "    'Forêt Aléatoire': y_pred_rf,\n",
    "    'XGBoost': y_pred_xgb,\n",
    "    'Réseau de Neurones (PyTorch)': all_preds\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for model_name, y_pred in predictions.items():\n",
    "    # Récupération des informations du rapport de classification sous forme de dictionnaire\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    precision_0 = report['0']['precision']\n",
    "    precision_1 = report['1']['precision']\n",
    "    recall_0 = report['0']['recall']\n",
    "    recall_1 = report['1']['recall']\n",
    "    f1_0 = report['0']['f1-score']\n",
    "    f1_1 = report['1']['f1-score']\n",
    "\n",
    "    results.append({\n",
    "        'Modèle': model_name,\n",
    "        'Précision False': precision_0,\n",
    "        'Précision True': precision_1,\n",
    "        'Recall False': recall_0,\n",
    "        'Recall True': recall_1,\n",
    "        'F1-Score False': f1_0,\n",
    "        'F1-Score True': f1_1\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **forêt aléatoire** semble obtenir les meilleurs résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "for i, (model_name, y_pred) in enumerate(predictions.items()):\n",
    "    ax = axes[i//3, i%3] \n",
    "    cm = confusion_matrix(y_test, y_pred)  # Calcul de la matrice de confusion\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='plasma', ax=ax)\n",
    "    ax.set_title(f'Matrice de Confusion - {model_name}')\n",
    "    ax.set_xlabel('Prédictions')\n",
    "    ax.set_ylabel('Vérités terrain')\n",
    "\n",
    "axes[1][2].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **forêt aléatoire** et **XGBoost** semblent légèrement meilleurs en termes de réduction des faux positifs et faux négatifs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **ROC-AUC Score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de tracer la courbe **ROC** à différents seuils de classification, on calcule les probabilités d'appartenance à chaque classe pour chaque observation. En pratique, seule la probabilité $P(classe=1)$ nous intéresse. Pour obtenir ces probabilités, nous pouvons utiliser la méthode `predict_proba` de `sklearn`. Cependant, notre **RN** ne dispose pas de cette méthode, nous allons donc calculer les **logits** puis les probabilités via la fonction **sigmoid**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = torch.FloatTensor(X_test.values.astype(float))\n",
    "with torch.no_grad():\n",
    "    logits = model(X_test_tensor) \n",
    "    probs_pytorch = F.sigmoid(logits).numpy()[:, 1]\n",
    "\n",
    "probabilities = {\n",
    "    'Régression Logistique': lr.predict_proba(X_test)[:, 1],\n",
    "    'Arbre de Décision': dt.predict_proba(X_test)[:, 1],\n",
    "    'Forêt Aléatoire': rf.predict_proba(X_test)[:, 1],\n",
    "    'XGBoost': xgb_model.predict_proba(X_test)[:, 1],\n",
    "    'Réseau de Neurones (PyTorch)': probs_pytorch\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for model_name, probs in probabilities.items():\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "    roc_auc = roc_auc_score(y_test, probs)\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Taux de Faux Positifs (FPR)')\n",
    "plt.ylabel('Taux de Vrais Positifs (TPR)')\n",
    "plt.title('Courbes ROC de plusieurs modèles')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce graphique montre que les modèles **Forêt Aléatoire**, **XGBoost** et les **Réseaux de Neurones** surpassent les autres en termes de capacité à distinguer les classes, avec des AUC proches de 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la suite, nous allons travailler sur le modèle de **Forêt Aléatoire**, car il offre les meilleurs résultats dans l'ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Optimisation des hyperparamètres**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a. Grid Search pour la Forêt Aléatoire**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le `Grid Search` est une technique visant à trouver les hyperparamètres optimaux d'un modèle en machine learning, en testant toutes les combinaisons possibles des hyperparamètres spécifiés et de déterminer celle qui donne les meilleures performances selon une métrique spécifique (comme la précision, le rappel, le F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les paramètres à tester\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'class_weight': ['balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "\n",
    "print(\"Meilleurs paramètres :\")\n",
    "pd.DataFrame(grid_search.best_params_, index=[\"Paramètres\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rf = {\n",
    "    'Forêt Aléatoire': y_pred_rf,\n",
    "    'Forêt Aléatoire (Grid Search)': y_pred_best_rf\n",
    "}\n",
    "results_rf = []\n",
    "\n",
    "for model_name, y_pred in predictions_rf.items():\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    precision_0 = report['0']['precision']\n",
    "    precision_1 = report['1']['precision']\n",
    "    recall_0 = report['0']['recall']\n",
    "    recall_1 = report['1']['recall']\n",
    "    f1_0 = report['0']['f1-score']\n",
    "    f1_1 = report['1']['f1-score']\n",
    "\n",
    "    results_rf.append({\n",
    "        'Modèle': model_name,\n",
    "        'Précision False': precision_0,\n",
    "        'Précision True': precision_1,\n",
    "        'Recall False': recall_0,\n",
    "        'Recall True': recall_1,\n",
    "        'F1-Score False': f1_0,\n",
    "        'F1-Score True': f1_1\n",
    "    })\n",
    "\n",
    "df_results_rf = pd.DataFrame(results_rf)\n",
    "df_results_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les performances sont extrêments proches avec notre modèle de départ. Seule le **F1-Score** connait une réelle amélioration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **b. Cross Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons réaliser un test de **robustesse** en utilisant la méthode de `Stratified K-Fold Cross-Validation`.\n",
    "\n",
    "En quoi cela consiste:\n",
    "- **Stratification** : Assure que chaque fold a approximativement la même proportion de chaque classe que l'ensemble de données initial.\n",
    "\n",
    "- **K-Fold** : L'ensemble de données est divisé en K sous-ensembles de taille égale.\n",
    "\n",
    "- **Cross Validation** : Cela consiste à entraîner et tester le modèle sur les sous-ensembles.\n",
    "\n",
    "Les objectifs sont les suivants:\n",
    "- **Estimation plus fiable** : Réduit la variance associée à une seule division entraînement/test.\n",
    "\n",
    "- __Utilisation efficace des données__ : Toutes les observations sont utilisées à la fois pour l'entraînement et le test.\n",
    "\n",
    "- **Détection du surapprentissage** : Permet de vérifier si le modèle généralise bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('scaler', StandardScaler()),  # Si nécessaire\n",
    "    ('classifier', best_rf)\n",
    "])\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    estimator=pipeline,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    cv=skf,\n",
    "    scoring=scoring,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "for metric in scoring.keys():\n",
    "    scores = cv_results[f'test_{metric}']\n",
    "    print(f\"{metric} : Moyenne = {scores.mean():.4f}, Écart-type = {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats en validation croisée montrent que le modèle n'est pas très stable et que ses performances sont peu robustes, surtout lorsque l'on regarde la `precision`, `recall` et `f1` sur différents sous-échantillons. Néanmoins, la performance moyenne légèrement inférieure à celle obtenue sur l'ensemble du dataset peut s'expliquer par le fait que le modèle est testé sur des portions trop petites des données lors de chaque itération."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IV. Analyse des résultats**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Importance des Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = best_rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Importance des caractéristiques\")\n",
    "sns.barplot(x=X_train.columns[indices][:10], y=importances[indices][:10])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PageValues` est de loin la variable la plus explicative. Cela est tout à fait cohérent, étant que **PageValues** est une valeur basée sur la probabilité qu'une page spécifique mène à une conversion, en se référant aux données historiques du site.\n",
    "\n",
    "On remarque que les **variables catégorielles** ne font pas partie des features les plus importantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Analyse des erreurs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons garder uniquement les **10 features** les plus importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = X_train.columns[indices][:10]\n",
    "\n",
    "# Ajout des vraies étiquettes et des prédictions\n",
    "X_test_df = X_test.copy()[top_features]\n",
    "X_test_df['True_Label'] = y_test.values\n",
    "X_test_df['Predicted_Label'] = y_pred_best_rf\n",
    "\n",
    "# Instances mal classées\n",
    "misclassified = X_test_df[X_test_df['True_Label'] != X_test_df['Predicted_Label']]\n",
    "print(f\"Nombre d'instances mal classées : {len(misclassified)} sur {len(X_test_df)} total\")\n",
    "\n",
    "# Instances bien classées\n",
    "correctly_classified = X_test_df[X_test_df['True_Label'] == X_test_df['Predicted_Label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut commencer par calculer les **moyennes** et **écarts-types** pour chaque variable en fonction de si elles ont été (ou non) correctement classifiées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moyennes et écarts-types pour les cas mal classés\n",
    "misclassified_stats = misclassified[top_features].describe().T[['mean', 'std']]\n",
    "\n",
    "# Moyennes et écarts-types pour les cas bien classés\n",
    "correctly_classified_stats = correctly_classified[top_features].describe().T[['mean', 'std']]\n",
    "\n",
    "# Comparaison des statistiques\n",
    "comparison_stats = misclassified_stats.join(correctly_classified_stats, lsuffix='_misclassified', rsuffix='_correctly_classified')\n",
    "comparison_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons observer les **densités** de distribution de chaque features en fonction de s'ils ont été correctement classifiés ou non.\n",
    "\n",
    "Cela nous permettra potentiellement de déterminer des caractéristiques sur les données qui ont amené à la mauvaise classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X_test_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_features.remove('True_Label')\n",
    "numeric_features.remove('Predicted_Label')\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i, feature in enumerate(numeric_features, 1):\n",
    "    \n",
    "    # Calcul de la limite pour l'axe x : 1.5 * l'écart-type autour de la moyenne\n",
    "    # pour inclure 99% des données et éliminer les valeurs aberrantes\n",
    "    min_val = min(comparison_stats.loc[feature, 'mean_misclassified'] - 1.5 * comparison_stats.loc[feature, 'std_misclassified'],\n",
    "                  comparison_stats.loc[feature, 'mean_correctly_classified'] - 1.5 * comparison_stats.loc[feature, 'std_correctly_classified'])\n",
    "    max_val = max(comparison_stats.loc[feature, 'mean_misclassified'] + 1.5 * comparison_stats.loc[feature, 'std_misclassified'],\n",
    "                  comparison_stats.loc[feature, 'mean_correctly_classified'] + 1.5 * comparison_stats.loc[feature, 'std_correctly_classified'])\n",
    "    \n",
    "    # Tracé des distributions de densité\n",
    "    plt.subplot(4, 4, i)\n",
    "    sns.kdeplot(data=correctly_classified, x=feature, label='Bien classés', fill=True)\n",
    "    sns.kdeplot(data=misclassified, x=feature, label='Mal classés', fill=True)\n",
    "    \n",
    "    # Définir la limite des axes en fonction de 1.5 * std\n",
    "    plt.xlim(min_val, max_val)\n",
    "    plt.title(f'Distribution de {feature}')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on regarde uniquement les quatres variables les plus importantes, on voit que les distributions entre `ProductRelated_Duration` et `Administrative` sont assez clairement distinctes, cependant, celles de `PageValues` et `ExitRates` ne le sont pas autant que ce dont on s'attendrait."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons réaliser des tests statistiques pour étudier ces distributions plus en détail. Si les `p-valeurs` sont proches de 0, cela signifie que les différences entre les distributions sont **significatives**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_data = []\n",
    "for feature in numeric_features:\n",
    "    stat, p_value = ks_2samp(correctly_classified[feature], misclassified[feature])\n",
    "    ks_data.append([f'{stat:.3f}', f'{p_value:.3f}'])\n",
    "pd.DataFrame(ks_data, columns=['Statistique KS', 'p-value'], index=numeric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les 8 **features** les plus importantes présentent des distribution significativement différentes. \n",
    "\n",
    "Cela met en lumière certains comportements de notre modèle, par exemple pour les cas mal classés, les distributions sont plus étalées avec des valeurs très basses et très élevées. Aussi, il semble y avoir une tendance où les moyennes des distributions des cas mal classés sont plus \"vers la droite\".\n",
    "\n",
    "En effet, on a déjà pu l'observer sur notre DataFrame de moyennes et écart-types, mais les distributions pour les cas mal classés ont tendance a avoir un `mean`et `std` plus élevé.\n",
    "\n",
    "Nous pourrions donc envisager de **segmenter** les données selon `PageValues` et entraîner des modèles spécifiques et ajouter des **transformations** pour mieux capturer les extrêmes. L'exploration de méthodes pour améliorer les performances de notre modèle seront explorées dans une seconde partie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **V. Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons utilisé différentes méthodes de machine learning pour prédire l'intention d'achat en ligne des utilisateurs en analysant le dataset \"Online Shoppers Purchasing Intention\". En appliquant diverses techniques de prétraitement, telles que l'encodage des variables catégorielles, la normalisation des variables numériques et la gestion du déséquilibre des classes via le sur-échantillonnage avec `SMOTE`, nous avons entraîné plusieurs modèles de classification. Parmi ces modèles, la **forêt aléatoire** et **XGBoost** ont démontré les meilleures performances, avec des scores `F1` élevés, indiquant une bonne capacité à distinguer les sessions aboutissant à un achat de celles qui n'y aboutissent pas.\n",
    "\n",
    "L'analyse des variables et des erreurs ont révélé que certaines *feature*, comme \"`PageValues`\" et \"`ProductRelated_Duration`\", étaient particulièrement déterminantes dans la prédiction. Cependant, le modèle a montré des limitations dans la classification correcte de certaines sessions, notamment celles présentant des comportements atypiques ou se situant aux extrêmes des distributions des variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **VI. Aller Plus Loin**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plusieurs axes d'amélioration peuvent être envisagés pour renforcer la robustesse et la précision du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Optimisation du traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ingénierie des caractéristiques avancée** : La création de nouvelles variables combinant des informations existantes pourrait aider à capturer des relations non linéaires ou des interactions complexes entre les variables.\n",
    "\n",
    "- **Transformation des variables** : L'application de transformations logarithmiques ou la normalisation robuste pourrait améliorer la gestion des valeurs extrêmes et réduire l'impact des outliers sur le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Intégration de méthodes de clusterisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Segmentation des sessions** : En utilisant des algorithmes de clusterisation tels que `K-Means` ou `DBSCAN`, nous pourrions identifier des groupes homogènes de sessions basés sur le comportement des utilisateurs.\n",
    "  \n",
    "- **Détection d'anomalies** : La clusterisation peut également aider à identifier des sessions atypiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gestion avancée du déséquilibre des classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Techniques d'ensemble** : L'utilisation de méthodes comme l'`EasyEnsemble` ou le `BalancedBaggingClassifier` pourrait améliorer les performances sur la classe minoritaire en combinant les prédictions de plusieurs modèles entraînés sur des sous-échantillons équilibrés.\n",
    "  \n",
    "- **Pondération des classes** : Ajuster les poids associés aux erreurs de classification pour pénaliser davantage les faux négatifs pourrait améliorer le rappel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
