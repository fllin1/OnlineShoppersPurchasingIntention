{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **0.Librairies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "# Modèles\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# XGBoost et LightGBM\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# UCI ML Repo\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **I. Formulation du problème**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Définition du problème**\n",
    "\n",
    "Nous allons utiliser le dataset [Online Shoppers Purchasing Intention](https://archive.ics.uci.edu/dataset/468/online+shoppers+purchasing+intention+dataset) pour prédire si une session d'un utilisateur aboutira à un achat ou non. Il s'agit donc d'un problème de **classification binaire**.\n",
    "\n",
    "- **Objectif :** Construire un modèle prédictif capable de classer les sessions en deux catégories :\n",
    "    - **Revenue = True** : la session se termine par un achat.\n",
    "    - **Revenue = False** : la session ne se termine pas par un achat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Formulation mathématique**\n",
    "\n",
    "Soit :\n",
    "- Un ensemble de données $X=\\{x_1,x_2,...,x_n\\}$ où chaque xi est un vecteur de caractéristiques représentant une session. \n",
    "- Une variable cible $Y=\\{y_1, y_2, ..., y_n\\}$ où $y_i \\in \\{0, 1\\}$ (0 pour \"pas d'achat\", 1 pour \"achat\").\n",
    "\n",
    "Le but est de trouver une fonction $f : X \\rightarrow Y$ telle que pour un nouvel exemple $x, f(x)$ prédit correctement $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **II. Exploration du dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des données \n",
    "online_shoppers_purchasing_intention_dataset = fetch_ucirepo(id=468) \n",
    "  \n",
    "# Récupérations des variables\n",
    "variables = online_shoppers_purchasing_intention_dataset.variables \n",
    "X = online_shoppers_purchasing_intention_dataset.data.features \n",
    "y = online_shoppers_purchasing_intention_dataset.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des données\n",
    "variables.to_csv('../data/online_shoppers_purchasing_intention_dataset.csv', index=False)\n",
    "X.to_csv('../data/features.csv', index=False)\n",
    "y.to_csv('../data/targets.csv', index=False)\n",
    "\n",
    "# Chargement des données\n",
    "variables = pd.read_csv('../data/online_shoppers_purchasing_intention_dataset.csv')\n",
    "X = pd.read_csv('../data/features.csv')\n",
    "y = pd.read_csv('../data/targets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Analyse exploratoire des données**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette partie est dédiée à la **compréhension générale des variables** et consistera en l'étude des:\n",
    "- **Variables numériques :** Analyse des distributions (moyenne, médiane, écart-type).\n",
    "- **Variables catégorielles :** Comptage des occurrences, encodage.\n",
    "\n",
    "*Selon la documentation, il n'y a aucune variable `Null`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a. Variables Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supproime les variables vides\n",
    "variables = variables[['name', 'role', 'type', 'missing_values']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **b. Target: Revenue (y)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y['Revenue'].sum()/len(y))\n",
    "\n",
    "# On affiche la distribution de la variable cible\n",
    "sns.countplot(x='Revenue', data=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que seulement **14,5%** des utilisateurs ont acheté."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **c. Features (X)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Informations générales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Visualisations initiales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation des features **numériques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "n = len(numeric_features)\n",
    "cols = 4\n",
    "rows = n // cols + (n % cols > 0)\n",
    "\n",
    "# Créer la figure et les sous-graphes\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "for i, feature in enumerate(numeric_features):\n",
    "    sns.histplot(X[feature], kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution de {feature}')\n",
    "for i in range(n, len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La majorité des distributions ont une forte concentration de données **proches de zéro**, particulièrement pour les interactions avec des pages spécifiques du site (pages administratives, informatives et produits). On peut supposer que que seulement une petite fraction des utilisateurs s'engagent sur ce types de pages.\n",
    "\n",
    "- L'analyse des taux de sortie et de rebond pourrait aider à **identifier des problèmes d'engagement**, notamment si certains types de pages (comme les pages de produits ou informatives) ont des taux de sortie plus élevés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "n = len(categorical_features)\n",
    "cols = 3\n",
    "\n",
    "# Créer la figure et les sous-graphes\n",
    "fig, axes = plt.subplots(1, cols, figsize=(16, 4))\n",
    "axes = axes.flatten()\n",
    "for i, feature in enumerate(categorical_features):\n",
    "    sns.histplot(X[feature], kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution de {feature}')\n",
    "for i in range(n, len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque plusieurs choses:\n",
    "- Un comportement de **saisonalité**, avec des pics au printemps et en automne.\n",
    "  \n",
    "- Une présence plus importante de **visiteurs réccurents**, cela indique que le site a un bon taux de fidélisation.\n",
    "  \n",
    "- Les achats semblent assez **équitablement répartis** au cours de la semaine, on retrouve une proportion cohérente d'environ 5/7 en semaine et 2/7 le week-end. Cela pourrait indiquer que le site est autant utilisé pour des activités professionnelles que récréatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aucune variable nulle dans les **features** et le **target** dataset, nous pouvons donc directement travailler sur les données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Détection de corrélations :**\n",
    "- Matrice de corrélation pour identifier les variables fortement liées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "correlation = X[numeric_features].corr()\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm')\n",
    "plt.title('Matrice de corrélation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corrélations fortes :**\n",
    "\n",
    "- **ProductRelated** et **ProductRelated_Duration** (0.86) : Il est logique que le nombre de pages de produits visitées soit fortement corrélé avec la durée passée sur ces pages. Plus les utilisateurs visitent de pages produits, plus ils passent de temps sur ces pages.\n",
    "\n",
    "- **BounceRates** et **ExitRates** (0.91) : Ces deux variables sont également très corrélées. Cela indique que les sessions avec un taux de rebond élevé ont tendance à se terminer rapidement (forte probabilité de quitter le site après avoir consulté peu de pages).\n",
    "\n",
    "**Corrélations modérées :**\n",
    "\n",
    "- **Informational** et **Informational_Duration** (0.62) : De même, une corrélation assez élevée entre le nombre de pages informatives visitées et la durée passée sur ces pages, ce qui est également intuitif.\n",
    "\n",
    "- **Administrative** et **Administrative_Duration** (0.6) : La relation entre le nombre de pages administratives visitées et la durée passée sur ces pages est modérée. Plus les utilisateurs interagissent avec des pages administratives, plus ils passent de temps sur ces pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([X, y], axis=1)\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i, feature in enumerate(numeric_features, 1):\n",
    "    plt.subplot(4, 4, i)\n",
    "    sns.violinplot(x='Revenue', y=feature, data=data, split=True)\n",
    "    plt.title(f'{feature} vs Revenue')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Pages produits** : Les variables liées aux pages produits (*ProductRelated* et *ProductRelated_Duration*) sont les meilleures variables pour différencier les utilisateurs générant des revenus de ceux qui n'en génèrent pas. Plus un utilisateur interagit avec les pages produits, plus il est susceptible de générer un revenu.\n",
    "\n",
    "- **Taux de rebond** et **taux de sortie** : Les utilisateurs qui génèrent des revenus tendent à avoir des taux de rebond et taux de sortie plus faibles, ce qui indique un engagement plus profond avec le site.\n",
    "\n",
    "- **PageValues** : C’est l'une des variables les plus discriminantes, les utilisateurs générant des revenus ayant des valeurs de page beaucoup plus élevées.\n",
    "\n",
    "- Les autres facteurs n'ont pas un impact significatif sur la génération de revenus, du moins dans cette visualisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **III. Modélisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Prétraitement des données**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a. Encodage des variables catégorielles**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir les variables binaires en entiers :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Weekend'] = data['Weekend'].astype(int)\n",
    "data['Revenue'] = data['Revenue'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "One-Hot Encoding pour les variables catégorielles avec plus de deux catégories :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['Month', 'VisitorType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **b. Normalisation ou standardisation des variables numériques**\n",
    "Standardisation pour uniformiser l'échelle des variables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data[numeric_features] = scaler.fit_transform(data[numeric_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **c. Gestion du déséquilibre des classes**\n",
    "SMOTE pour sur-échantillonner la classe minoritaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Revenue', axis=1)\n",
    "y = data['Revenue']\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **d. Division des données en ensembles d'entraînement et de test**\n",
    "Séparation les données en ensembles d'entraînement et de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, \n",
    "    y_resampled, \n",
    "    test_size=0.3, # 30% des données pour le test\n",
    "    random_state=42, # Fixer le random_state pour obtenir les mêmes résultats\n",
    "    stratify=y_resampled # Stratification pour conserver la distribution de la variable cible\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Algorithmes de Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utliser les méthodes suivantes classiques puis comparer leurs performances:\n",
    "- Régression Logistique\n",
    "- Arbre de Décision\n",
    "- Forêt Aléatoire\n",
    "- XGBoost\n",
    "- Réseau de Neurones avec PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a. Implémentation des modèles**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Régression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arbre de Décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forêt Aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RN avec PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les données en tenseurs\n",
    "X_train_tensor = torch.tensor(X_train.values.astype(float), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values.astype(float), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Créer des DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.layer1(x))\n",
    "        out = self.relu(self.layer2(out))\n",
    "        out = self.output(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size=X_train.shape[1])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        all_preds.extend(predicted.numpy())\n",
    "    \n",
    "    print(f'Accuracy du réseau sur les données de test : {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **b. Évaluation des modèles**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La précision seule perd en fiabilité dans un scénario où les classes sont déséquilibrées. Nous allons donc utiliser 3 méthodes d'évaluation qui sont particulirement pertinentes dans ce cas, et importées de `sklearn.metrics`: \n",
    "\n",
    "- `classification_report`:\n",
    "  - la **précision** du modèle (proportion des prédictions positives qui sont correctes).\n",
    "  - le **recall** (proportion des vrais positifs qui sont correctement prédits).\n",
    "  - le **f1-score** (moyenne harmonique de la précision et du rappel).\n",
    "\n",
    "- `confusion_matrix`: affiche au sein d'une matrice 2x2 les **True Positives**, **True Negatives**, **False Positives** et **False Negatives**.\n",
    "\n",
    "- `roc_auc_score`: **ROC** (Receiver Operating Characteristic) est le tracé de **True Positive Ratio** contre **False Positive Ratio** pour chaque seuil de classification possible entre 0 et 1 (dans la pratique, à des intervalles choisis). L'**AUC** est l'aire sous la courbe ROC, plus il est proche de 1, plus le modèle est performant, et s'il est proche de 0.5, cela équivaut à une classification aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {\n",
    "    'Régression Logistique': y_pred_lr,\n",
    "    'Arbre de Décision': y_pred_dt,\n",
    "    'Forêt Aléatoire': y_pred_rf,\n",
    "    'XGBoost': y_pred_xgb,\n",
    "    'Réseau de Neurones (PyTorch)': all_preds\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for model_name, y_pred in predictions.items():\n",
    "    # Récupération des informations du rapport de classification sous forme de dictionnaire\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    precision_0 = report['0']['precision']\n",
    "    precision_1 = report['1']['precision']\n",
    "    recall_0 = report['0']['recall']\n",
    "    recall_1 = report['1']['recall']\n",
    "    f1_0 = report['0']['f1-score']\n",
    "    f1_1 = report['1']['f1-score']\n",
    "\n",
    "    results.append({\n",
    "        'Modèle': model_name,\n",
    "        'Précision False': precision_0,\n",
    "        'Précision True': precision_1,\n",
    "        'Recall False': recall_0,\n",
    "        'Recall True': recall_1,\n",
    "        'F1-Score False': f1_0,\n",
    "        'F1-Score True': f1_1\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **forêt aléatoire** semble obtenir les meilleurs résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "for i, (model_name, y_pred) in enumerate(predictions.items()):\n",
    "    ax = axes[i//3, i%3] \n",
    "    cm = confusion_matrix(y_test, y_pred)  # Calcul de la matrice de confusion\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='plasma', ax=ax)\n",
    "    ax.set_title(f'Matrice de Confusion - {model_name}')\n",
    "    ax.set_xlabel('Prédictions')\n",
    "    ax.set_ylabel('Vérités terrain')\n",
    "\n",
    "axes[1][2].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **forêt aléatoire** et **XGBoost** semblent légèrement meilleurs en termes de réduction des faux positifs et faux négatifs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **ROC-AUC Score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de tracer la courbe **ROC** à différents seuils de classification, on calcule les probabilités d'appartenance à chaque classe pour chaque observation. En pratique, seule la probabilité $P(classe=1)$ nous intéresse. Pour obtenir ces probabilités, nous pouvons utiliser la méthode `predict_proba` de `sklearn`. Cependant, notre **RN** ne dispose pas de cette méthode, nous allons donc calculer les **logits** puis les probabilités via la fonction **sigmoid**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = torch.FloatTensor(X_test.values.astype(float))\n",
    "with torch.no_grad():\n",
    "    logits = model(X_test_tensor) \n",
    "    probs_pytorch = F.sigmoid(logits).numpy()[:, 1]\n",
    "\n",
    "probabilities = {\n",
    "    'Régression Logistique': lr.predict_proba(X_test)[:, 1],\n",
    "    'Arbre de Décision': dt.predict_proba(X_test)[:, 1],\n",
    "    'Forêt Aléatoire': rf.predict_proba(X_test)[:, 1],\n",
    "    'XGBoost': xgb_model.predict_proba(X_test)[:, 1],\n",
    "    'Réseau de Neurones (PyTorch)': probs_pytorch\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for model_name, probs in probabilities.items():\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "    roc_auc = roc_auc_score(y_test, probs)\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Taux de Faux Positifs (FPR)')\n",
    "plt.ylabel('Taux de Vrais Positifs (TPR)')\n",
    "plt.title('Courbes ROC de plusieurs modèles')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce graphique montre que les modèles **Forêt Aléatoire**, **XGBoost** et les **Réseaux de Neurones** surpassent les autres en termes de capacité à distinguer les classes, avec des AUC proches de 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle **Forêt Aléatoire** nous apparaît comme étant le plus performant pour résoudre cette tâche de classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
